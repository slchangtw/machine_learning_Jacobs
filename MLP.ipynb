{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"define a layer object\"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, random_seed=42):\n",
    "        \"\"\"Constructer of a layer object\"\"\"\n",
    "        \n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        self.weights = np.random.uniform(-0.43, 0.43, size=(self.n_input, self.n_output))\n",
    "\n",
    "    def _sigmoid_forward(self, x):\n",
    "        \"\"\"Apply sigmoid function\"\"\"\n",
    "        \n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _tanh_forward(self, x):\n",
    "        \"\"\"Apply tanh function\"\"\"\n",
    "        \n",
    "        return (np.exp(2*x) - 1) / (np.exp(2*x) + 1)\n",
    "    \n",
    "    def forward_prop(self, input_x, activation_func='sigmoid', add_noise=False):\n",
    "        \"\"\"Implement forward propagation\"\"\"\n",
    "        \n",
    "        # add gaussian noises to input\n",
    "        if add_noise:\n",
    "            input_x += np.random.normal(0, 0.045, size=input_x.shape)\n",
    "        \n",
    "        if activation_func == 'sigmoid':\n",
    "            self.out_x = self._sigmoid_forward(input_x.dot(self.weights))\n",
    "        elif activation_func == 'tanh':\n",
    "            self.out_x = self._tanh_forward(input_x.dot(self.weights))\n",
    "\n",
    "    def backward_prop(self, x_pre, delta_next, weights_next, eta, activation_func='sigmoid'):\n",
    "        \"\"\"Implement backward propagation\"\"\"\n",
    "        \n",
    "        if activation_func == 'sigmoid':\n",
    "            self.delta = self.out_x * (1-self.out_x) * delta_next.dot(weights_next.T)\n",
    "        elif activation_func == 'tanh':\n",
    "            self.delta = (1 - np.square(self._tanh_forward(self.out_x))) * delta_next.dot(weights_next.T)\n",
    "        \n",
    "        self.weights -= eta * x_pre.T.dot(self.delta) / x_pre.shape[0]\n",
    "    \n",
    "class Softmax_Layer(Layer):\n",
    "    \"\"\"define a output layer object\"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, random_seed=42):\n",
    "        \"\"\"Constructer of a output layer object\"\"\"\n",
    "            \n",
    "        Layer.__init__(self, n_input, n_output, random_seed)\n",
    "    \n",
    "    def _softmax(self, out_x):\n",
    "        return np.exp(out_x) / np.sum(np.exp(out_x))\n",
    "    \n",
    "    def forward_prop(self, input_x):\n",
    "        \"\"\"Implement forward propagation\"\"\"\n",
    "        \n",
    "        self.out_x = input_x.dot(self.weights)\n",
    "        \n",
    "    def backward_prop(self, y_true, y_preds, x_pre, eta):\n",
    "        \"\"\"Implement backward propagation (output layer)\"\"\"\n",
    "        \n",
    "        self.delta = 2 * (y_preds - y_true)\n",
    "        \n",
    "        self.weights -= eta * x_pre.T.dot(self.delta) / x_pre.shape[0]\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"Predict labels\"\"\"\n",
    "        \n",
    "        self.pred_proba = np.apply_along_axis(self._softmax, 1, self.out_x)\n",
    "        return (self.pred_proba == self.pred_proba.max(axis=1)[:, None]).astype(int)\n",
    "    \n",
    "    def compute_mse(self, y_true):\n",
    "        \"\"\"Compute mean square error\"\"\"\n",
    "        \n",
    "        return np.mean(np.square(self.out_x - y_true))\n",
    "    \n",
    "    def compute_miscla_rate(self, y_true):\n",
    "        \"\"\"Compute misclassification rate\"\"\"\n",
    "        \n",
    "        return 1 - np.sum(np.all(output_layer.predict() == y_true, axis=1)) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]])\n",
    "y = np.array([[0, 1], [1, 0], [1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "n_neurons = 2\n",
    "fc_layer = Layer(X.shape[1], n_neurons)\n",
    "output_layer = Softmax_Layer(n_neurons, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(epochs)\n",
    "for epoch in range(epochs):\n",
    "    fc_layer.forward_prop(X)\n",
    "    output_layer.forward_prop(fc_layer.out_x)\n",
    "    \n",
    "    y_preds = output_layer.predict()\n",
    "    output_layer.backward_prop(y, y_preds, x_pre=fc_layer.out_x, eta=0.035)\n",
    "    fc_layer.backward_prop(x_pre=X, delta_next=output_layer.delta, weights_next=output_layer.weights, eta=0.035)\n",
    "    \n",
    "    errors[epoch] = output_layer.compute_mse(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11282eda0>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = np.loadtxt('input/mfeat-pix.txt')\n",
    "\n",
    "# normalize data\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "# X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "\n",
    "# add bias term\n",
    "X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "# split the dataset into training data and test data\n",
    "train_indices = [range(0 + 200*i, 100 + 200*i) for i in range(10)]\n",
    "test_indices = [range(100 + 200*i, 200 + 200*i) for i in range(10)]\n",
    "\n",
    "X_train = X[train_indices, ].reshape(1000, 241)\n",
    "X_test = X[test_indices, ].reshape(1000, 241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class labels\n",
    "nb_classes = 10\n",
    "y_vector = np.array([i for i in range(10) for j in range(100)])\n",
    "y_matrix = np.eye(nb_classes)[y_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the architecture\n",
    "epochs = 10000\n",
    "neurons_1 = 256\n",
    "neurons_2 = 256\n",
    "fc_layer1 = Layer(X.shape[1], neurons_1)\n",
    "fc_layer2 = Layer(neurons_1, neurons_2)\n",
    "output_layer = Softmax_Layer(neurons_2, 10)\n",
    "\n",
    "train_miss = np.zeros(epochs)\n",
    "test_miss = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.924 0.876\n",
      "10 0.44399999999999995 0.43999999999999995\n",
      "20 0.28900000000000003 0.29800000000000004\n",
      "30 0.23199999999999998 0.247\n",
      "40 0.18600000000000005 0.20799999999999996\n",
      "50 0.15500000000000003 0.18700000000000006\n",
      "60 0.15200000000000002 0.17500000000000004\n",
      "70 0.133 0.16200000000000003\n",
      "80 0.10999999999999999 0.14700000000000002\n",
      "90 0.10299999999999998 0.14300000000000002\n",
      "100 0.11499999999999999 0.139\n",
      "110 0.10299999999999998 0.129\n",
      "120 0.09099999999999997 0.124\n",
      "130 0.09099999999999997 0.122\n",
      "140 0.09399999999999997 0.11699999999999999\n",
      "150 0.10299999999999998 0.11499999999999999\n",
      "160 0.09199999999999997 0.11399999999999999\n",
      "170 0.10199999999999998 0.10799999999999998\n",
      "180 0.09599999999999997 0.10799999999999998\n",
      "190 0.08299999999999996 0.10199999999999998\n",
      "200 0.07799999999999996 0.09999999999999998\n",
      "210 0.08799999999999997 0.09499999999999997\n",
      "220 0.07699999999999996 0.09199999999999997\n",
      "230 0.07299999999999995 0.09099999999999997\n",
      "240 0.07499999999999996 0.08899999999999997\n",
      "250 0.07699999999999996 0.08999999999999997\n",
      "260 0.07199999999999995 0.08799999999999997\n",
      "270 0.07199999999999995 0.08399999999999996\n",
      "280 0.07699999999999996 0.08099999999999996\n",
      "290 0.06599999999999995 0.08399999999999996\n",
      "300 0.06499999999999995 0.07999999999999996\n",
      "310 0.06299999999999994 0.07699999999999996\n",
      "320 0.061000000000000054 0.07699999999999996\n",
      "330 0.07199999999999995 0.07499999999999996\n",
      "340 0.08099999999999996 0.07399999999999995\n",
      "350 0.06799999999999995 0.07399999999999995\n",
      "360 0.06899999999999995 0.07299999999999995\n",
      "370 0.06000000000000005 0.07299999999999995\n",
      "380 0.05600000000000005 0.07099999999999995\n",
      "390 0.061000000000000054 0.07099999999999995\n",
      "400 0.05500000000000005 0.07199999999999995\n",
      "410 0.06999999999999995 0.07299999999999995\n",
      "420 0.05800000000000005 0.07099999999999995\n",
      "430 0.052000000000000046 0.06999999999999995\n",
      "440 0.05700000000000005 0.06999999999999995\n",
      "450 0.05300000000000005 0.06799999999999995\n",
      "460 0.06399999999999995 0.06799999999999995\n",
      "470 0.06399999999999995 0.06599999999999995\n",
      "480 0.07499999999999996 0.06599999999999995\n",
      "490 0.06899999999999995 0.06699999999999995\n",
      "500 0.06599999999999995 0.06699999999999995\n",
      "510 0.05800000000000005 0.06699999999999995\n",
      "520 0.05700000000000005 0.06699999999999995\n",
      "530 0.05400000000000005 0.06799999999999995\n",
      "540 0.04800000000000004 0.06799999999999995\n",
      "550 0.052000000000000046 0.06799999999999995\n",
      "560 0.05600000000000005 0.06599999999999995\n",
      "570 0.04700000000000004 0.06799999999999995\n",
      "580 0.062000000000000055 0.06699999999999995\n",
      "590 0.05700000000000005 0.06699999999999995\n",
      "600 0.05700000000000005 0.06599999999999995\n",
      "610 0.05500000000000005 0.06699999999999995\n",
      "620 0.05900000000000005 0.06499999999999995\n",
      "630 0.052000000000000046 0.06299999999999994\n",
      "640 0.06000000000000005 0.06000000000000005\n",
      "650 0.052000000000000046 0.06399999999999995\n",
      "660 0.062000000000000055 0.06599999999999995\n",
      "670 0.06000000000000005 0.06499999999999995\n",
      "680 0.05700000000000005 0.06499999999999995\n",
      "690 0.06499999999999995 0.06299999999999994\n",
      "700 0.04700000000000004 0.06399999999999995\n",
      "710 0.06499999999999995 0.06299999999999994\n",
      "720 0.05900000000000005 0.06299999999999994\n",
      "730 0.05400000000000005 0.06499999999999995\n",
      "740 0.04700000000000004 0.06399999999999995\n",
      "750 0.05800000000000005 0.06499999999999995\n",
      "760 0.050000000000000044 0.06599999999999995\n",
      "770 0.04400000000000004 0.06399999999999995\n",
      "780 0.050000000000000044 0.06299999999999994\n",
      "790 0.04700000000000004 0.06299999999999994\n",
      "800 0.04200000000000004 0.06299999999999994\n",
      "810 0.05700000000000005 0.062000000000000055\n",
      "820 0.04400000000000004 0.06299999999999994\n",
      "830 0.049000000000000044 0.06299999999999994\n",
      "840 0.052000000000000046 0.06000000000000005\n",
      "850 0.04400000000000004 0.05800000000000005\n",
      "860 0.041000000000000036 0.05600000000000005\n",
      "870 0.040000000000000036 0.05700000000000005\n",
      "880 0.039000000000000035 0.05500000000000005\n",
      "890 0.03600000000000003 0.05600000000000005\n",
      "900 0.03600000000000003 0.05700000000000005\n",
      "910 0.039000000000000035 0.05600000000000005\n",
      "920 0.04600000000000004 0.05600000000000005\n",
      "930 0.039000000000000035 0.05600000000000005\n",
      "940 0.04400000000000004 0.05600000000000005\n",
      "950 0.04300000000000004 0.05600000000000005\n",
      "960 0.04400000000000004 0.05500000000000005\n",
      "970 0.03500000000000003 0.05800000000000005\n",
      "980 0.04500000000000004 0.05700000000000005\n",
      "990 0.039000000000000035 0.05900000000000005\n",
      "1000 0.04500000000000004 0.06000000000000005\n",
      "1010 0.029000000000000026 0.062000000000000055\n",
      "1020 0.04500000000000004 0.062000000000000055\n",
      "1030 0.03500000000000003 0.061000000000000054\n",
      "1040 0.052000000000000046 0.062000000000000055\n",
      "1050 0.040000000000000036 0.061000000000000054\n",
      "1060 0.04800000000000004 0.061000000000000054\n",
      "1070 0.04800000000000004 0.062000000000000055\n",
      "1080 0.04700000000000004 0.062000000000000055\n",
      "1090 0.04200000000000004 0.062000000000000055\n",
      "1100 0.041000000000000036 0.062000000000000055\n",
      "1110 0.040000000000000036 0.05700000000000005\n",
      "1120 0.04500000000000004 0.05600000000000005\n",
      "1130 0.040000000000000036 0.05600000000000005\n",
      "1140 0.03300000000000003 0.05700000000000005\n",
      "1150 0.03300000000000003 0.05800000000000005\n",
      "1160 0.03400000000000003 0.05800000000000005\n",
      "1170 0.029000000000000026 0.05600000000000005\n",
      "1180 0.041000000000000036 0.05600000000000005\n",
      "1190 0.03400000000000003 0.05600000000000005\n",
      "1200 0.03200000000000003 0.05600000000000005\n",
      "1210 0.038000000000000034 0.05600000000000005\n",
      "1220 0.031000000000000028 0.05800000000000005\n",
      "1230 0.030000000000000027 0.05800000000000005\n",
      "1240 0.041000000000000036 0.05500000000000005\n",
      "1250 0.03300000000000003 0.05600000000000005\n",
      "1260 0.04200000000000004 0.05700000000000005\n",
      "1270 0.03600000000000003 0.05300000000000005\n",
      "1280 0.04500000000000004 0.05600000000000005\n",
      "1290 0.040000000000000036 0.05500000000000005\n",
      "1300 0.03700000000000003 0.05600000000000005\n",
      "1310 0.03300000000000003 0.05700000000000005\n",
      "1320 0.028000000000000025 0.05700000000000005\n",
      "1330 0.03300000000000003 0.05800000000000005\n",
      "1340 0.04200000000000004 0.05900000000000005\n",
      "1350 0.03400000000000003 0.06000000000000005\n",
      "1360 0.039000000000000035 0.06000000000000005\n",
      "1370 0.039000000000000035 0.06000000000000005\n",
      "1380 0.03300000000000003 0.061000000000000054\n",
      "1390 0.041000000000000036 0.061000000000000054\n",
      "1400 0.03400000000000003 0.061000000000000054\n",
      "1410 0.04300000000000004 0.062000000000000055\n",
      "1420 0.031000000000000028 0.06299999999999994\n",
      "1430 0.04500000000000004 0.06399999999999995\n",
      "1440 0.03300000000000003 0.06299999999999994\n",
      "1450 0.038000000000000034 0.06299999999999994\n",
      "1460 0.03300000000000003 0.06299999999999994\n",
      "1470 0.03600000000000003 0.06299999999999994\n",
      "1480 0.04600000000000004 0.06299999999999994\n",
      "1490 0.041000000000000036 0.06299999999999994\n",
      "1500 0.03600000000000003 0.06399999999999995\n",
      "1510 0.030000000000000027 0.06299999999999994\n",
      "1520 0.038000000000000034 0.06399999999999995\n",
      "1530 0.03500000000000003 0.06499999999999995\n",
      "1540 0.03500000000000003 0.06399999999999995\n",
      "1550 0.04800000000000004 0.062000000000000055\n",
      "1560 0.03400000000000003 0.06399999999999995\n",
      "1570 0.03500000000000003 0.06499999999999995\n",
      "1580 0.030000000000000027 0.06499999999999995\n",
      "1590 0.040000000000000036 0.06499999999999995\n",
      "1600 0.03300000000000003 0.06499999999999995\n",
      "1610 0.03400000000000003 0.06399999999999995\n",
      "1620 0.030000000000000027 0.06399999999999995\n",
      "1630 0.027000000000000024 0.06299999999999994\n",
      "1640 0.03600000000000003 0.06299999999999994\n",
      "1650 0.03600000000000003 0.06399999999999995\n",
      "1660 0.028000000000000025 0.06399999999999995\n",
      "1670 0.028000000000000025 0.062000000000000055\n",
      "1680 0.03200000000000003 0.061000000000000054\n",
      "1690 0.03600000000000003 0.062000000000000055\n",
      "1700 0.027000000000000024 0.062000000000000055\n",
      "1710 0.030000000000000027 0.062000000000000055\n",
      "1720 0.031000000000000028 0.06299999999999994\n",
      "1730 0.028000000000000025 0.06399999999999995\n",
      "1740 0.03300000000000003 0.06499999999999995\n",
      "1750 0.030000000000000027 0.06299999999999994\n",
      "1760 0.028000000000000025 0.06399999999999995\n",
      "1770 0.040000000000000036 0.06299999999999994\n",
      "1780 0.039000000000000035 0.06299999999999994\n",
      "1790 0.03600000000000003 0.06299999999999994\n",
      "1800 0.028000000000000025 0.06399999999999995\n",
      "1810 0.03300000000000003 0.06399999999999995\n",
      "1820 0.03200000000000003 0.06399999999999995\n",
      "1830 0.051000000000000045 0.06399999999999995\n",
      "1840 0.041000000000000036 0.06299999999999994\n",
      "1850 0.03700000000000003 0.06499999999999995\n",
      "1860 0.04500000000000004 0.06299999999999994\n",
      "1870 0.03500000000000003 0.06499999999999995\n",
      "1880 0.04300000000000004 0.06499999999999995\n",
      "1890 0.040000000000000036 0.06499999999999995\n",
      "1900 0.029000000000000026 0.06599999999999995\n",
      "1910 0.03500000000000003 0.06499999999999995\n",
      "1920 0.03600000000000003 0.06399999999999995\n",
      "1930 0.038000000000000034 0.06299999999999994\n",
      "1940 0.04300000000000004 0.06299999999999994\n",
      "1950 0.039000000000000035 0.06299999999999994\n",
      "1960 0.026000000000000023 0.06399999999999995\n",
      "1970 0.03200000000000003 0.06499999999999995\n",
      "1980 0.038000000000000034 0.06499999999999995\n",
      "1990 0.03200000000000003 0.06299999999999994\n",
      "2000 0.026000000000000023 0.062000000000000055\n",
      "2010 0.03500000000000003 0.06299999999999994\n",
      "2020 0.03500000000000003 0.06299999999999994\n",
      "2030 0.02300000000000002 0.06299999999999994\n",
      "2040 0.03200000000000003 0.06299999999999994\n",
      "2050 0.03600000000000003 0.061000000000000054\n",
      "2060 0.030000000000000027 0.06399999999999995\n",
      "2070 0.038000000000000034 0.06299999999999994\n",
      "2080 0.03300000000000003 0.06299999999999994\n",
      "2090 0.03300000000000003 0.06299999999999994\n",
      "2100 0.03200000000000003 0.06000000000000005\n",
      "2110 0.03200000000000003 0.062000000000000055\n",
      "2120 0.028000000000000025 0.062000000000000055\n",
      "2130 0.03600000000000003 0.062000000000000055\n",
      "2140 0.03700000000000003 0.062000000000000055\n",
      "2150 0.03400000000000003 0.062000000000000055\n",
      "2160 0.02100000000000002 0.061000000000000054\n",
      "2170 0.027000000000000024 0.06000000000000005\n",
      "2180 0.028000000000000025 0.061000000000000054\n",
      "2190 0.027000000000000024 0.061000000000000054\n",
      "2200 0.027000000000000024 0.062000000000000055\n",
      "2210 0.03200000000000003 0.061000000000000054\n",
      "2220 0.025000000000000022 0.06000000000000005\n",
      "2230 0.03300000000000003 0.06000000000000005\n",
      "2240 0.029000000000000026 0.061000000000000054\n",
      "2250 0.027000000000000024 0.06000000000000005\n",
      "2260 0.03300000000000003 0.06000000000000005\n",
      "2270 0.03500000000000003 0.061000000000000054\n",
      "2280 0.030000000000000027 0.061000000000000054\n",
      "2290 0.031000000000000028 0.061000000000000054\n",
      "2300 0.03200000000000003 0.061000000000000054\n",
      "2310 0.03500000000000003 0.062000000000000055\n",
      "2320 0.02200000000000002 0.062000000000000055\n",
      "2330 0.03300000000000003 0.061000000000000054\n",
      "2340 0.025000000000000022 0.05800000000000005\n",
      "2350 0.028000000000000025 0.05900000000000005\n",
      "2360 0.02300000000000002 0.05900000000000005\n",
      "2370 0.030000000000000027 0.05900000000000005\n",
      "2380 0.02400000000000002 0.05900000000000005\n",
      "2390 0.025000000000000022 0.05900000000000005\n",
      "2400 0.027000000000000024 0.05700000000000005\n",
      "2410 0.02400000000000002 0.05800000000000005\n",
      "2420 0.029000000000000026 0.05700000000000005\n",
      "2430 0.026000000000000023 0.05800000000000005\n",
      "2440 0.02100000000000002 0.05900000000000005\n",
      "2450 0.02400000000000002 0.05900000000000005\n",
      "2460 0.026000000000000023 0.061000000000000054\n",
      "2470 0.029000000000000026 0.062000000000000055\n",
      "2480 0.02100000000000002 0.062000000000000055\n",
      "2490 0.025000000000000022 0.06299999999999994\n",
      "2500 0.02100000000000002 0.06399999999999995\n",
      "2510 0.018000000000000016 0.06399999999999995\n",
      "2520 0.027000000000000024 0.06399999999999995\n",
      "2530 0.026000000000000023 0.06499999999999995\n",
      "2540 0.029000000000000026 0.06599999999999995\n",
      "2550 0.026000000000000023 0.06699999999999995\n",
      "2560 0.020000000000000018 0.06499999999999995\n",
      "2570 0.025000000000000022 0.06599999999999995\n",
      "2580 0.02300000000000002 0.06399999999999995\n",
      "2590 0.031000000000000028 0.06499999999999995\n",
      "2600 0.040000000000000036 0.06499999999999995\n",
      "2610 0.029000000000000026 0.06399999999999995\n",
      "2620 0.031000000000000028 0.06499999999999995\n",
      "2630 0.02300000000000002 0.06399999999999995\n",
      "2640 0.03200000000000003 0.06399999999999995\n",
      "2650 0.03200000000000003 0.06499999999999995\n",
      "2660 0.03400000000000003 0.06399999999999995\n",
      "2670 0.05400000000000005 0.06499999999999995\n",
      "2680 0.03200000000000003 0.06299999999999994\n",
      "2690 0.02400000000000002 0.06399999999999995\n",
      "2700 0.02300000000000002 0.06599999999999995\n",
      "2710 0.030000000000000027 0.06499999999999995\n",
      "2720 0.031000000000000028 0.06499999999999995\n",
      "2730 0.025000000000000022 0.06499999999999995\n",
      "2740 0.029000000000000026 0.06399999999999995\n",
      "2750 0.031000000000000028 0.06499999999999995\n",
      "2760 0.02100000000000002 0.06499999999999995\n",
      "2770 0.031000000000000028 0.06499999999999995\n",
      "2780 0.020000000000000018 0.06499999999999995\n",
      "2790 0.02100000000000002 0.06599999999999995\n",
      "2800 0.028000000000000025 0.06499999999999995\n",
      "2810 0.015000000000000013 0.06499999999999995\n",
      "2820 0.02300000000000002 0.06399999999999995\n",
      "2830 0.025000000000000022 0.06399999999999995\n",
      "2840 0.027000000000000024 0.06399999999999995\n",
      "2850 0.02200000000000002 0.06299999999999994\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    fc_layer1.forward_prop(X_train, activation_func='tanh', add_noise=True)\n",
    "    fc_layer2.forward_prop(fc_layer1.out_x, activation_func='tanh', add_noise=True)\n",
    "    output_layer.forward_prop(fc_layer2.out_x)\n",
    "    \n",
    "    train_miss[epoch] = output_layer.compute_miscla_rate(y_matrix)\n",
    "    \n",
    "    output_layer.backward_prop(y_matrix, output_layer.predict(), x_pre=fc_layer2.out_x, eta=0.004)\n",
    "    fc_layer2.backward_prop(x_pre=fc_layer1.out_x, activation_func='tanh', delta_next=output_layer.delta, weights_next=output_layer.weights, eta=0.01)\n",
    "    fc_layer1.backward_prop(x_pre=X_train, activation_func='tanh', delta_next=fc_layer2.delta, weights_next=fc_layer2.weights, eta=0.01)\n",
    "    \n",
    "    fc_layer1.forward_prop(X_test, activation_func='tanh')\n",
    "    fc_layer2.forward_prop(fc_layer1.out_x, activation_func='tanh')\n",
    "    output_layer.forward_prop(fc_layer2.out_x)\n",
    "    \n",
    "    test_miss[epoch] = output_layer.compute_miscla_rate(y_matrix)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, train_miss[epoch], test_miss[epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
