{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"define a layer object\"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, random_seed=42):\n",
    "        \"\"\"Constructer of a layer object\"\"\"\n",
    "        \n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        self.weights = np.random.rand(self.n_input, self.n_output)\n",
    "\n",
    "    def _sigmoid_forward(self, x):\n",
    "        \"\"\"Apply sigmoid function\"\"\"\n",
    "        \n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward_prop(self, input_x, activation_func='sigmoid'):\n",
    "        \"\"\"Implement forward propagation\"\"\"\n",
    "        \n",
    "        if activation_func == 'sigmoid':\n",
    "            self.out_x = self._sigmoid_forward(input_x.dot(self.weights))\n",
    "    \n",
    "    def backward_prop(self, out_x, delta_next, weights_next, eta):\n",
    "        \"\"\"Implement backward propagation\"\"\"\n",
    "        \n",
    "        self.delta = out_x.dot((1-out_x).T).dot(delta_next).dot(weights_next.T)\n",
    "        \n",
    "        self.weights -= eta * out_x.T.dot(self.delta)\n",
    "        \n",
    "class Output_Layer(Layer):\n",
    "    \"\"\"define a output layer object\"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, n_output=None, random_seed=42):\n",
    "        \"\"\"Constructer of a output layer object\"\"\"\n",
    "            \n",
    "        Layer.__init__(self, n_input, n_output, random_seed)\n",
    "    \n",
    "    def _softmax(self, out_x):\n",
    "        return np.exp(out_x) / np.sum(np.exp(out_x), axis=1)\n",
    "    \n",
    "    def backward_prop(self, y_true, y_preds, out_x, eta):\n",
    "        \"\"\"Implement backward propagation (output layer)\"\"\"\n",
    "        \n",
    "        self.delta = 2 * (y_true - y_preds)\n",
    "        \n",
    "        self.weights -= eta * out_x.T.dot(self.delta)\n",
    "    \n",
    "    def predict(self, y_true):\n",
    "        \"\"\"Predict labels\"\"\"\n",
    "        \n",
    "        # self.pred_prop = self._softmax(self.out_x)\n",
    "        return np.where(self.out_x > 0.5, 1, 0)\n",
    "    \n",
    "    def compute_mse(self, y_true):\n",
    "        return np.mean(np.square(self.out_x - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]])\n",
    "y = np.array([1, 0, 0, 1])\n",
    "y = y.reshape(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_neurons = 3\n",
    "fc_layer = Layer(X.shape[1], n_neurons)\n",
    "output_layer = Output_Layer(n_neurons, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3575064513046198\n",
      "0.4124304435143616\n",
      "0.45630217084143715\n",
      "0.48062813672561727\n",
      "0.4918013196014277\n",
      "0.49658563539638756\n",
      "0.4985866902717198\n",
      "0.4994164078579353\n",
      "0.49975924473621613\n",
      "0.49990070795055674\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    fc_layer.forward_prop(X)\n",
    "    output_layer.forward_prop(fc.out_x)\n",
    "    \n",
    "    y_preds = output_layer.predict(y)\n",
    "    print(output_layer.compute_mse(y))\n",
    "\n",
    "    output_layer.backward_prop(y, y_preds, fc_layer.out_x, 0.1)\n",
    "    fc_layer.backward_prop(out_x=X, delta_next=output_layer.delta, weights_next=output_layer.weights, eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
